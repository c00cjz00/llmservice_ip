app:
  description: "請分別請模型扮演 User / AI Model ， 客戶主題放置於 `<subject></subject>` XML 標籤中，\n\
    根據客戶主題，生成歷史對話，以延續對話為目標，一次僅生成一筆回覆。\n以此迭代多次。其中可以指定 User / AI Model 的回答風格 (口語、正式、專業口吻……等，來增加內容的多樣性)\n\
    請遵守以下 step1 到step10 的規範, 你可以依據實際對話狀況, 判斷是否需要新增或刪減對話step次數\nstep 1: generate_subtopic\n\
    step 2: generate_source_question\nstep 3: generate 1st user\nstep 4: generate\
    \ 1st assistant\nstep 5: generate 2nd user\nstep 6: generate 2st assistant\nstep\
    \ 7: generate 3rd user\nstep 8: generate 3rd assistant\nstep 9: generate 4th user\n\
    step 10: generate 4th assistant\n...\n\n請依照`<export></export>` XML 標籤中json格式輸出\
    \ (LLM對話微調通用的格式), 只需要輸出json 格式資料, 不要包含  XML 標籤,  且不要有其他建議或說明\n\n<export>\n{\n\
    \  \"conversation\": [\n    {\"role\": \"system\", \"content\": \"Subtopic: ...\"\
    },\n    {\"role\": \"system\", \"content\": \"Source Question: ...\"},\n    {\"\
    role\": \"user\",\"content\": \"...\"},\n    {\"role\": \"assistant\",\"content\"\
    : \"...\"},\n\t......\n  ]\n}\n</export>\n\n<subject>\n{{user_question}}\n</subject>\n\
    \n"
  icon: 🤖
  icon_background: '#FFEAD5'
  mode: completion
  name: 17-文字生成_question2question(多輪對話)
  use_icon_as_answer_icon: false
kind: app
model_config:
  agent_mode:
    enabled: false
    max_iteration: 5
    strategy: react
    tools: []
  annotation_reply:
    enabled: false
  chat_prompt_config: {}
  completion_prompt_config: {}
  dataset_configs:
    datasets:
      datasets: []
    reranking_enable: true
    retrieval_model: multiple
    top_k: 4
  dataset_query_variable: ''
  external_data_tools: []
  file_upload:
    allowed_file_extensions:
    - .JPG
    - .JPEG
    - .PNG
    - .GIF
    - .WEBP
    - .SVG
    allowed_file_types:
    - image
    allowed_file_upload_methods:
    - remote_url
    - local_file
    enabled: false
    image:
      detail: high
      enabled: false
      number_limits: 3
      transfer_methods:
      - remote_url
      - local_file
    number_limits: 3
  model:
    completion_params:
      stop: []
    mode: chat
    name: llama-3.2-90b-text-preview
    provider: groq
  more_like_this:
    enabled: false
  opening_statement: null
  pre_prompt: "請分別請模型扮演 User / AI Model ， 客戶主題放置於 `<subject></subject>` XML 標籤中，\n\
    根據客戶主題，生成歷史對話，以延續對話為目標，一次僅生成一筆回覆。\n以此迭代多次。其中可以指定 User / AI Model 的回答風格 (口語、正式、專業口吻……等，來增加內容的多樣性)\n\
    請遵守以下 step1 到step10 的規範, 你可以依據實際對話狀況, 判斷是否需要新增或刪減對話step次數\nstep 1: generate_subtopic\n\
    step 2: generate_source_question\nstep 3: generate 1st user\nstep 4: generate\
    \ 1st assistant\nstep 5: generate 2nd user\nstep 6: generate 2st assistant\nstep\
    \ 7: generate 3rd user\nstep 8: generate 3rd assistant\nstep 9: generate 4th user\n\
    step 10: generate 4th assistant\n...\n\n請依照`<export></export>` XML 標籤中json格式輸出\
    \ (LLM對話微調通用的格式), 只需要輸出json 格式資料, 不要包含  XML 標籤,  且不要有其他建議或說明\n\n<export>\n{\n\
    \  \"conversation\": [\n    {\"role\": \"system\", \"content\": \"Subtopic: ...\"\
    },\n    {\"role\": \"system\", \"content\": \"Source Question: ...\"},\n    {\"\
    role\": \"user\",\"content\": \"...\"},\n    {\"role\": \"assistant\",\"content\"\
    : \"...\"},\n\t......\n  ]\n}\n</export>\n\n<subject>\n{{user_question}}\n</subject>\n\
    \n"
  prompt_type: simple
  retriever_resource:
    enabled: true
  sensitive_word_avoidance:
    configs: []
    enabled: false
    type: ''
  speech_to_text:
    enabled: false
  suggested_questions: []
  suggested_questions_after_answer:
    enabled: false
  text_to_speech:
    enabled: false
    language: ''
    voice: ''
  user_input_form:
  - text-input:
      default: ''
      label: 題目
      required: true
      variable: user_question
version: 0.1.2
