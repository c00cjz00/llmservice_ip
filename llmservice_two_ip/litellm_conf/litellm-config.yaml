model_list:
  - model_name: Llama3-TAIDE-e.2.0.0
    litellm_params:
      model: openai/Llama3-TAIDE-e.2.0.0
      api_base: "https://td.nchc.org.tw/api/v1"
      api_key: "APIKEY"
  - model_name: Llama3-TAIDE-LX-8B-Chat-Alpha1
    litellm_params:
      model: openai/Llama3-TAIDE-LX-8B-Chat-Alpha1
      api_base: "https://td.nchc.org.tw/api/v1"
      api_key: "APIKEY"
  - model_name: taide-llama2-70b   
    litellm_params:
      model: openai/taide-llama2-70b
      api_base: "https://td.nchc.org.tw/api/v1"
      api_key: "APIKEY"
  - model_name: TAIDE/k.0.1.0
    litellm_params:
      model: openai/TAIDE/k.0.1.0
      api_base: "https://td.nchc.org.tw/api/v1"
      api_key: "APIKEY"
  - model_name: TAIDE/t.0.1.0
    litellm_params:
      model: openai/TAIDE/t.0.1.0
      api_base: "https://td.nchc.org.tw/api/v1"
      api_key: "APIKEY"
  - model_name: TAIDE/l.0.1.0
    litellm_params:
      model: openai/TAIDE/l.0.1.0
      api_base: "https://td.nchc.org.tw/api/v1"
      api_key: "APIKEY"
      input_cost_per_token: 0.02 
      output_cost_per_token: 0.06 

litellm_settings:
  num_retries: 30 # retry call 3 times on each model_name (e.g. zephyr-beta)
  request_timeout: 10 # raise Timeout error if call takes longer than 10s. Sets litellm.request_timeout 
  allowed_fails: 3 # cooldown model if it fails > 1 call in a minute. 

general_settings:
  master_key: sk_live_nchc123456789 # [OPTIONAL] Use to enforce auth on proxy. See - https://docs.litellm.ai/docs/proxy/virtual_keys
  store_model_in_db: True
  proxy_budget_rescheduler_min_time: 60
  proxy_budget_rescheduler_max_time: 64
  proxy_batch_write_at: 1
  database_connection_pool_limit: 10
  database_url: "postgresql://nchc:nchcservice@host.docker.internal:5432/litellm" # [OPTIONAL] use for token-based auth to proxy

  